# On the Consistency of Video Large Language Models in Temporal Comprehension

[![arXiv](https://img.shields.io/badge/arXiv-2411.12951-b31b1b.svg)](https://arxiv.org/abs/2411.12951)

## News
- [x] **[2024.11.20]** Our paper has been released on arXiv.
- [ ] Release the dataset and code. Additionally, we will provide more evaluation results of Video-LLMs.

## Citation
If you find our paper useful, please consider citing our paper.
```BibTeX
@article{jung2024consistency,
  title={On the Consistency of Video Large Language Models in Temporal Comprehension},
  author={Jung, Minjoon and Xiao, Junbin and Zhang, Byoung-Tak and Yao, Angela},
  journal={arXiv preprint arXiv:2411.12951},
  year={2024}
}
```
## Acknowledgement
We appreciate for the following awesome Video-LLMs: 
- [TimeChat](https://github.com/RenShuhuai-Andy/TimeChat) 
- [VTimeLLM](https://github.com/huangb23/VTimeLLM)
- [VTG-LLM](https://github.com/gyxxyg/VTG-LLM)
- [Video-LLaMA](https://github.com/DAMO-NLP-SG/Video-LLaMA)
- [Video-LLaMA2](https://github.com/DAMO-NLP-SG/VideoLLaMA2)
- [Video-LLaVA](https://github.com/PKU-YuanGroup/Video-LLaVA)
- [Video-ChatGPT](https://github.com/mbzuai-oryx/Video-ChatGPT)
- [VideoChat2](https://github.com/OpenGVLab/Ask-Anything/tree/main/video_chat2)
